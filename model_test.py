from transformers import AutoTokenizer, AutoModelForSequenceClassification, LukeConfig
import torch
tokenizer = AutoTokenizer.from_pretrained("Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime")
config = LukeConfig.from_pretrained('Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime', output_hidden_states=True)    
model = AutoModelForSequenceClassification.from_pretrained('Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime', config=config)

# print(config)

text='ğŸ˜†'

max_seq_length=512
token=tokenizer(text,
        truncation=True,
        max_length=max_seq_length,
        padding="max_length",
        return_tensors="pt")
output=model(token['input_ids'], token['attention_mask'])
max_index=torch.argmax(torch.tensor(output.logits))
print(torch.tensor(output.logits))

if max_index==0:
    print('joyã€ã†ã‚Œã—ã„')
elif max_index==1:
    print('sadnessã€æ‚²ã—ã„')
elif max_index==2:
    print('anticipationã€æœŸå¾…')
elif max_index==3:
    print('surpriseã€é©šã')
elif max_index==4:
    print('angerã€æ€’ã‚Š')
elif max_index==5:
    print('fearã€æã‚Œ')
elif max_index==6:
    print('disgustã€å«Œæ‚ª')
elif max_index==7:
    print('trustã€ä¿¡é ¼')